import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
import joblib
import os

print("="*70)
print("DATA PREPROCESSING - TELCO CUSTOMER CHURN")
print("="*70)

# Load data
file_path = os.path.join('data', 'telecom_churn.csv')
df = pd.read_csv(file_path)
print(f"\nğŸ“Š Original dataset shape: {df.shape}")

# Check for any remaining missing values
print(f"\nğŸ” Checking for missing values...")
missing = df.isnull().sum()
if missing.sum() > 0:
    print("Missing values found:")
    print(missing[missing > 0])
else:
    print("âœ… No missing values")

# Separate features and target
X = df.drop('Churn', axis=1)
y = df['Churn']

print(f"\nğŸ“‹ Features shape: {X.shape}")
print(f"ğŸ¯ Target shape: {y.shape}")

# Identify column types
categorical_cols = X.select_dtypes(include=['object']).columns.tolist()
numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()

print(f"\nğŸ“ Categorical features ({len(categorical_cols)}):")
for col in categorical_cols:
    print(f"   â€¢ {col}: {X[col].nunique()} unique values")

print(f"\nğŸ”¢ Numerical features ({len(numerical_cols)}):")
for col in numerical_cols:
    print(f"   â€¢ {col}: range [{X[col].min():.2f}, {X[col].max():.2f}]")

# Encode categorical variables
print(f"\nğŸ”„ Encoding categorical variables...")
label_encoders = {}
X_encoded = X.copy()

for col in categorical_cols:
    le = LabelEncoder()
    X_encoded[col] = le.fit_transform(X[col].astype(str))
    label_encoders[col] = le
    print(f"   âœ“ {col}: {list(le.classes_)[:3]}{'...' if len(le.classes_) > 3 else ''}")

# Save encoders
joblib.dump(label_encoders, 'label_encoders.pkl')
print(f"\nğŸ’¾ Label encoders saved to 'label_encoders.pkl'")

# Split data (80% train, 20% test)
print(f"\nâœ‚ï¸  Splitting data (80% train, 20% test)...")
X_train, X_test, y_train, y_test = train_test_split(
    X_encoded, y, 
    test_size=0.2, 
    random_state=42, 
    stratify=y  # Maintain same churn ratio in both sets
)

print(f"\nğŸ“¦ Dataset splits:")
print(f"   â€¢ Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(df)*100:.1f}%)")
print(f"   â€¢ Test set: {X_test.shape[0]} samples ({X_test.shape[0]/len(df)*100:.1f}%)")
print(f"\n   â€¢ Train churn rate: {y_train.mean()*100:.2f}%")
print(f"   â€¢ Test churn rate: {y_test.mean()*100:.2f}%")

# Scale numerical features (important for model performance!)
print(f"\nâš–ï¸  Scaling numerical features...")
scaler = StandardScaler()
X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])
X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])

print(f"   âœ“ Scaled {len(numerical_cols)} numerical features")

# Save scaler
joblib.dump(scaler, 'scaler.pkl')
joblib.dump(numerical_cols, 'numerical_cols.pkl')  # Save column names too
print(f"   ğŸ’¾ Scaler saved to 'scaler.pkl'")

# Save processed data
X_train.to_csv('X_train.csv', index=False)
X_test.to_csv('X_test.csv', index=False)
y_train.to_csv('y_train.csv', index=False)
y_test.to_csv('y_test.csv', index=False)

print(f"\nğŸ’¾ Preprocessed data saved:")
print(f"   â€¢ X_train.csv")
print(f"   â€¢ X_test.csv")
print(f"   â€¢ y_train.csv")
print(f"   â€¢ y_test.csv")

print("\n" + "="*70)
print("âœ… PREPROCESSING COMPLETE!")
print("="*70)
print("\nYou're ready to train models! Run: python train_model.py")